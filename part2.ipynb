{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "36cdef1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.random import dirichlet\n",
    "from scipy.special import logsumexp\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import adjusted_rand_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9fb56c",
   "metadata": {},
   "source": [
    "# read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "836061d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = pd.read_csv(\"./data/Q3/mixture1.geno\", header=None).values\n",
    "Xnew_df = pd.read_csv(\"./data/Q3/mixture2.geno\", header=None).values\n",
    "F_df = pd.read_csv(\"./data/Q3/mixture1.freq\", header=None).values\n",
    "Z_df = pd.read_csv(\"./data/Q3/mixture1.ganc\", header=None).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53a2772",
   "metadata": {},
   "source": [
    "# implementation M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "d1d7aea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.394 0.606]\n",
      "[[0.79187817 0.00660066]\n",
      " [0.63959391 0.00825083]\n",
      " [0.24619289 0.5379538 ]\n",
      " [0.27664975 0.34488449]\n",
      " [0.08375635 0.36963696]\n",
      " [0.22335025 0.03630363]\n",
      " [0.33756345 0.49339934]\n",
      " [0.49746193 0.48514851]\n",
      " [0.37817259 0.62706271]\n",
      " [0.59390863 0.34983498]\n",
      " [0.35532995 0.05610561]\n",
      " [0.1928934  0.21122112]\n",
      " [0.04822335 0.2359736 ]\n",
      " [0.17258883 0.97689769]\n",
      " [0.43147208 0.53630363]\n",
      " [0.10152284 0.02145215]\n",
      " [0.35532995 0.74587459]\n",
      " [0.46700508 0.3960396 ]\n",
      " [0.32994924 0.11386139]\n",
      " [0.24873096 0.52475248]\n",
      " [0.50507614 0.4950495 ]\n",
      " [0.35279188 0.15841584]\n",
      " [0.28680203 0.72607261]\n",
      " [0.14467005 0.47524752]\n",
      " [0.65736041 0.23927393]\n",
      " [0.29695431 0.48514851]\n",
      " [0.36040609 0.36963696]\n",
      " [0.58883249 0.47854785]\n",
      " [0.10152284 0.11551155]\n",
      " [0.35532995 0.00660066]\n",
      " [0.32741117 0.45214521]\n",
      " [0.06598985 0.1039604 ]\n",
      " [0.02538071 0.15676568]\n",
      " [0.45685279 0.56270627]\n",
      " [0.04060914 0.20132013]\n",
      " [0.13451777 0.71287129]\n",
      " [0.4035533  0.57590759]\n",
      " [0.40862944 0.51485149]\n",
      " [0.5964467  0.35478548]\n",
      " [0.11928934 0.1039604 ]\n",
      " [0.54314721 0.58085809]\n",
      " [0.04568528 0.1980198 ]\n",
      " [0.44670051 0.37293729]\n",
      " [0.24111675 0.5       ]\n",
      " [0.42893401 0.52970297]\n",
      " [0.49746193 0.62541254]\n",
      " [0.16243655 0.15346535]\n",
      " [0.41878173 0.67326733]\n",
      " [0.26903553 0.09735974]\n",
      " [0.15736041 0.32013201]\n",
      " [0.35279188 0.17161716]\n",
      " [0.54568528 0.32508251]\n",
      " [0.50761421 0.32838284]\n",
      " [0.38071066 0.37293729]\n",
      " [0.48730964 0.09075908]\n",
      " [0.43654822 0.09405941]\n",
      " [0.42893401 0.82013201]\n",
      " [0.49746193 0.06270627]\n",
      " [0.03807107 0.51980198]\n",
      " [0.45939086 0.2029703 ]\n",
      " [0.02284264 0.01155116]\n",
      " [0.38324873 0.02475248]\n",
      " [0.48984772 0.52805281]\n",
      " [0.03553299 0.58580858]\n",
      " [0.47715736 0.12046205]\n",
      " [0.0786802  0.13861386]\n",
      " [0.14467005 0.05610561]\n",
      " [0.15736041 0.35643564]\n",
      " [0.14720812 0.35313531]\n",
      " [0.12944162 0.52805281]\n",
      " [0.52791878 0.33993399]\n",
      " [0.43654822 0.03465347]\n",
      " [0.52538071 0.0330033 ]\n",
      " [0.04314721 0.17821782]\n",
      " [0.2106599  0.04950495]\n",
      " [0.44670051 0.96369637]\n",
      " [0.10659898 0.39933993]\n",
      " [0.25380711 0.13531353]\n",
      " [0.52284264 0.34158416]\n",
      " [0.52538071 0.14686469]\n",
      " [0.17258883 0.21617162]\n",
      " [0.35532995 0.32178218]\n",
      " [0.13705584 0.11056106]\n",
      " [0.01015228 0.48844884]\n",
      " [0.33756345 0.03135314]\n",
      " [0.43654822 0.53960396]\n",
      " [0.05837563 0.14686469]\n",
      " [0.48477157 0.51155116]\n",
      " [0.03553299 0.16006601]\n",
      " [0.57614213 0.22937294]\n",
      " [0.45685279 0.01155116]\n",
      " [0.17258883 0.01650165]\n",
      " [0.46700508 0.5049505 ]\n",
      " [0.06345178 0.04950495]\n",
      " [0.09137056 0.51155116]\n",
      " [0.14213198 0.47854785]\n",
      " [0.46446701 0.33663366]\n",
      " [0.26649746 0.27227723]\n",
      " [0.60659898 0.12706271]\n",
      " [0.3071066  0.50165017]\n",
      " [0.01522843 0.22277228]\n",
      " [0.11928934 0.12871287]\n",
      " [0.04314721 0.13861386]\n",
      " [0.25634518 0.1039604 ]\n",
      " [0.46954315 0.14356436]\n",
      " [0.38324873 0.40924092]\n",
      " [0.06852792 0.12706271]\n",
      " [0.02284264 0.06435644]\n",
      " [0.59898477 0.21947195]\n",
      " [0.45177665 0.61551155]\n",
      " [0.29441624 0.17821782]\n",
      " [0.05583756 0.0990099 ]\n",
      " [0.32233503 0.06270627]\n",
      " [0.30456853 0.71287129]\n",
      " [0.15482234 0.14026403]\n",
      " [0.13959391 0.36468647]\n",
      " [0.27664975 0.10066007]\n",
      " [0.15736041 0.55610561]\n",
      " [0.08629442 0.25577558]\n",
      " [0.05329949 0.0330033 ]\n",
      " [0.56852792 0.64026403]\n",
      " [0.1319797  0.07425743]\n",
      " [0.6928934  0.33333333]\n",
      " [0.48984772 0.5379538 ]\n",
      " [0.04314721 0.03960396]\n",
      " [0.20050761 0.3630363 ]\n",
      " [0.1142132  0.12871287]\n",
      " [0.11928934 0.32343234]\n",
      " [0.29695431 0.17161716]\n",
      " [0.10406091 0.50165017]\n",
      " [0.66497462 0.21122112]\n",
      " [0.48984772 0.28052805]\n",
      " [0.53299492 0.6980198 ]\n",
      " [0.18527919 0.79042904]\n",
      " [0.57360406 0.19141914]\n",
      " [0.6142132  0.54785479]\n",
      " [0.10152284 0.09240924]\n",
      " [0.6142132  0.24587459]\n",
      " [0.14720812 0.34818482]\n",
      " [0.02538071 0.38778878]\n",
      " [0.02791878 0.13036304]\n",
      " [0.27411168 0.24587459]\n",
      " [0.37817259 0.35148515]\n",
      " [0.08883249 0.22937294]\n",
      " [0.55329949 0.22442244]\n",
      " [0.33248731 0.18646865]\n",
      " [0.21827411 0.30363036]\n",
      " [0.57360406 0.18151815]\n",
      " [0.56598985 0.46369637]\n",
      " [0.49492386 0.20132013]\n",
      " [0.53299492 0.56270627]\n",
      " [0.4035533  0.37623762]\n",
      " [0.56091371 0.46864686]\n",
      " [0.44923858 0.29042904]\n",
      " [0.4822335  0.42739274]\n",
      " [0.37309645 0.32508251]\n",
      " [0.42893401 0.5379538 ]\n",
      " [0.46446701 0.37788779]\n",
      " [0.47208122 0.45214521]\n",
      " [0.32741117 0.2970297 ]\n",
      " [0.44416244 0.52310231]\n",
      " [0.01522843 0.39273927]\n",
      " [0.14720812 0.24092409]\n",
      " [0.35279188 0.12871287]\n",
      " [0.03299492 0.15346535]\n",
      " [0.01269036 0.5379538 ]\n",
      " [0.10406091 0.05115512]\n",
      " [0.11928934 0.37458746]\n",
      " [0.26142132 0.5379538 ]\n",
      " [0.18020305 0.69306931]\n",
      " [0.08375635 0.01155116]\n",
      " [0.47461929 0.58415842]\n",
      " [0.5786802  0.42079208]\n",
      " [0.41624365 0.27887789]\n",
      " [0.30964467 0.45544554]\n",
      " [0.5964467  0.21782178]\n",
      " [0.35279188 0.41254125]\n",
      " [0.15989848 0.04455446]\n",
      " [0.18781726 0.00825083]\n",
      " [0.29187817 0.12706271]\n",
      " [0.20558376 0.97194719]\n",
      " [0.34263959 0.01815182]\n",
      " [0.10152284 0.08415842]\n",
      " [0.50507614 0.15346535]\n",
      " [0.46446701 0.06105611]\n",
      " [0.54314721 0.54620462]\n",
      " [0.61167513 0.49174917]\n",
      " [0.29441624 0.15676568]\n",
      " [0.12690355 0.33168317]\n",
      " [0.03299492 0.30528053]\n",
      " [0.44162437 0.42244224]\n",
      " [0.29695431 0.73267327]\n",
      " [0.09898477 0.16006601]\n",
      " [0.00507614 0.00330033]\n",
      " [0.18274112 0.32013201]\n",
      " [0.15989848 0.25082508]\n",
      " [0.5786802  0.10891089]\n",
      " [0.39593909 0.24257426]\n",
      " [0.50253807 0.43729373]\n",
      " [0.43147208 0.64026403]\n",
      " [0.44923858 0.59570957]\n",
      " [0.35279188 0.72277228]\n",
      " [0.01015228 0.11221122]\n",
      " [0.00253807 0.62211221]\n",
      " [0.17766497 0.47689769]\n",
      " [0.1142132  0.54455446]\n",
      " [0.0786802  0.07425743]\n",
      " [0.48730964 0.05115512]\n",
      " [0.16751269 0.04455446]\n",
      " [0.32994924 0.33333333]\n",
      " [0.19796954 0.35808581]\n",
      " [0.26649746 0.02310231]\n",
      " [0.28680203 0.27557756]\n",
      " [0.19796954 0.37788779]\n",
      " [0.57106599 0.28382838]\n",
      " [0.50253807 0.52640264]\n",
      " [0.34010152 0.31683168]\n",
      " [0.03807107 0.06435644]\n",
      " [0.47969543 0.25742574]\n",
      " [0.30456853 0.6369637 ]\n",
      " [0.19796954 0.02145215]\n",
      " [0.20558376 0.14191419]\n",
      " [0.35532995 0.14686469]\n",
      " [0.06598985 0.24257426]\n",
      " [0.42385787 0.33168317]\n",
      " [0.54060914 0.39933993]\n",
      " [0.5        0.41914191]\n",
      " [0.06345178 0.34488449]\n",
      " [0.16751269 0.24422442]\n",
      " [0.22081218 0.169967  ]\n",
      " [0.32741117 0.74587459]\n",
      " [0.19543147 0.2359736 ]\n",
      " [0.05076142 0.67326733]\n",
      " [0.2893401  0.04290429]\n",
      " [0.04060914 0.330033  ]\n",
      " [0.12436548 0.169967  ]\n",
      " [0.48477157 0.54620462]\n",
      " [0.23350254 0.29207921]\n",
      " [0.51015228 0.51320132]\n",
      " [0.09898477 0.16336634]\n",
      " [0.0964467  0.02970297]\n",
      " [0.05583756 0.14686469]\n",
      " [0.04822335 0.12376238]\n",
      " [0.05076142 0.03135314]\n",
      " [0.17005076 0.07755776]\n",
      " [0.17766497 0.54455446]\n",
      " [0.14213198 0.39108911]\n",
      " [0.50253807 0.43234323]\n",
      " [0.18274112 0.1650165 ]\n",
      " [0.22588832 0.05280528]]\n"
     ]
    }
   ],
   "source": [
    "#X: N by M data matrix\n",
    "#gamma: P(Z_i=k | X_i=x_i, theta) N by K\n",
    "def M_step(X, gamma): \n",
    "    N, M = X.shape\n",
    "    K = gamma.shape[1]\n",
    "    \n",
    "    ######### TODO 3a: modify the following to have meaning updates #########\n",
    "    pis = np.empty(K)\n",
    "    F = np.empty(shape=(M, K)) # frequency matrix: M by K\n",
    "\n",
    "    # Update pi -- pi[k] = proportion of all individuals coming from population k\n",
    "    for k in range(K):\n",
    "        pis[k] = np.mean(gamma[:, k])\n",
    "\n",
    "\n",
    "    # Iterate through each population\n",
    "    for k in range(K):\n",
    "        partial_ass_sum = np.sum(gamma[:, k]) # sum up partial assignments across all individuals in population (# individuals in population)\n",
    "        # Iterate through each SNP\n",
    "        for j in range(M):\n",
    "            if partial_ass_sum == 0:\n",
    "                F[j][k] = 0\n",
    "            else:\n",
    "                # Iterate through each individual\n",
    "                partial_ass_sum_SNP_j = 0 # num of 1 genos at SNP j across all individuals belomnging to population \n",
    "                for i in range(N):\n",
    "                    partial_ass_sum_SNP_j += gamma[i][k] * X[i][j] # Multiply soft assignment to population k for individual i by genotype\n",
    "                F[j][k] = partial_ass_sum_SNP_j / partial_ass_sum\n",
    "    \n",
    "    \n",
    "    ######### End of modification #########     \n",
    "    return ({\"pis\": pis, \"F\": F})\n",
    "\n",
    "gamma = Z_df\n",
    "result = M_step(X_df, gamma)\n",
    "# print (result)\n",
    "print (result[\"pis\"])\n",
    "print (result[\"F\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0d4de2",
   "metadata": {},
   "source": [
    "# implementation E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "a20b3fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X: N by M data matrix\n",
    "#params: a dictionary with two parameters returned from M_step\n",
    "def E_step(X, params, thr=10**(-8)):\n",
    "    F = params[\"F\"] # frequency matrix F: M by K\n",
    "    pis = params[\"pis\"] # proportion vector pi: length K\n",
    "\n",
    "    N, M = X.shape\n",
    "    K = F.shape[1] \n",
    "\n",
    "    ######### TODO 3b: modify the following to have meaning updates #########\n",
    "    #calculate weighted_log_prob: log(P(X_i=x_i | Z_i=k, theta) * P(Z_i=k | theta))\n",
    "    #calcualte log_prob_sample: log P(Xi=x_i | theta) length N vector. Hint: use logsumexp function\n",
    "    #calcualte log_prob_data: log P(X_1:n=x_1:n | theta) scalar\n",
    "    #calculate log_gammas: log P(Z_i=k | X_i=x_i, theta) N by K\n",
    "    weighted_log_prob = np.zeros((N, K))\n",
    "    for i in range(N):\n",
    "        for k in range(K):\n",
    "            prod = 1\n",
    "            for j in range(M):\n",
    "                allele_freq = thr\n",
    "                if F[j][k] != 0:\n",
    "                    allele_freq = F[j][k]\n",
    "                one_minus = thr\n",
    "                if 1 - allele_freq != 0:\n",
    "                    one_minus = 1 - allele_freq\n",
    "                prod *= (allele_freq ** X[i][j]) * (one_minus ** (1 - X[i][j]))\n",
    "            weighted_log_prob[i][k] = np.log(prod) + np.log(pis[k])\n",
    "\n",
    "    log_prob_sample = np.zeros(N)\n",
    "    for i in range(N):\n",
    "        log_prob_sample[i] = logsumexp(weighted_log_prob[i])\n",
    "\n",
    "    log_prob_data = np.sum(log_prob_sample)\n",
    "\n",
    "    log_gammas = np.zeros((N, K))\n",
    "    for k in range(K):\n",
    "        for i in range(N):\n",
    "            log_gammas[i][k] = weighted_log_prob[i][k] - log_prob_sample[i]\n",
    "\n",
    "    ######### end of modification #########\n",
    "    return log_gammas, log_prob_data\n",
    "\n",
    "params = {\"F\": F_df, \"pis\": result[\"pis\"]}\n",
    "E_results = E_step(X_df, params)\n",
    "log_gammas = E_results[0]\n",
    "\n",
    "N = X_df.shape[0]\n",
    "\n",
    "predicted_ancestry = np.empty(N)\n",
    "for i in range(N):\n",
    "    predicted_ancestry[i] = np.argmax(log_gammas[i])\n",
    "\n",
    "actual_ancestry = np.empty(N)\n",
    "for i in range(N):\n",
    "    actual_ancestry[i] = np.argmax(Z_df[i])\n",
    "\n",
    "print (adjusted_rand_score(actual_ancestry, predicted_ancestry))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798c1b86",
   "metadata": {},
   "source": [
    "# implementation EM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "7701c7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EM(X, K = 2, max_iter = 100, tol = 10**(-4), n_init = 3, debug = False):\n",
    "    \n",
    "    N, M = X.shape \n",
    "    res = {}\n",
    "    best_log_prob_data = -np.inf\n",
    "    converged  = False \n",
    "\n",
    "    predicted_ancestries = []\n",
    "    best_pis = None\n",
    "\n",
    "    #loop through different random starting points\n",
    "    for init in range(1, 1+n_init, 1):\n",
    "        np.random.seed(init)\n",
    "        if debug:\n",
    "            print(f\"starting EM on random initialization: {init} out of {n_init}\")\n",
    "        \n",
    "        ######### TODO 3c: modify the following to have the full EM updates #########\n",
    "        \n",
    "        #initialize soft assignment \n",
    "        gammas = np.empty(shape=(N, K))\n",
    "        start_gammas = gammas\n",
    "        \n",
    "        for i in range(N):\n",
    "            gammas[i] = dirichlet([1] * K)\n",
    "\n",
    "        \n",
    "        \n",
    "        log_prob_data = -np.inf\n",
    "        all_log_likelihoods = []\n",
    "        for n_iter in range(1, 1+max_iter, 1):\n",
    "            prev_log_prob_data = log_prob_data\n",
    "\n",
    "            M_results = M_step(X, gammas) # pis and allele frequency matrices\n",
    "            \n",
    "            log_gammas, log_prob_data = E_step(X, M_results)\n",
    "\n",
    "            all_log_likelihoods.append(log_prob_data)\n",
    "\n",
    "            gammas = np.exp(log_gammas)\n",
    "        \n",
    "            ######### convergence check #########\n",
    "            change = (log_prob_data - prev_log_prob_data) / N\n",
    "            if abs(change) < tol:\n",
    "                if debug:\n",
    "                    print(f\"random initialization {init} converged at iteration {n_iter}\")\n",
    "                    print(\"\")\n",
    "                converged = True\n",
    "                break\n",
    "        \n",
    "        plt.scatter([i for i in range(len(all_log_likelihoods))], all_log_likelihoods)\n",
    "        plt.title(f\"Log Likelihood vs Iteration, for Iteration {init}\")\n",
    "        plt.xlabel(\"Iteration\")\n",
    "        plt.ylabel(\"Log Likelihood\")\n",
    "        plt.show()\n",
    "\n",
    "        ######### update on the best initialization #########\n",
    "        if log_prob_data > best_log_prob_data:\n",
    "            best_log_prob_data = log_prob_data\n",
    "            best_init = start_gammas\n",
    "            best_pis = M_results[\"pis\"]\n",
    "\n",
    "        print (f\"Iteration {init}\")\n",
    "        print (f\"Best init gamma: {best_init}\")\n",
    "        print (f\"Best log likelihood: {best_log_prob_data}\")\n",
    "\n",
    "        # best_init = NULL\n",
    "\n",
    "        predicted_ancestry = np.empty(N)\n",
    "        for i in range(N):\n",
    "            predicted_ancestry[i] = np.argmax(gammas[i])\n",
    "        predicted_ancestries.append(predicted_ancestry)\n",
    "         \n",
    "        \n",
    "    ######### end of modification #########\n",
    "    res[\"converged\"] = converged     \n",
    "    res[\"best_init\"] = best_init\n",
    "    res[\"predicted_ancestries\"] = predicted_ancestries\n",
    "    res[\"best_log_likelihood\"] = best_log_prob_data  \n",
    "    res[\"best_pis\"] = best_pis\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8d0ba9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "8446c053",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_df[:, [i for i in range(10)]] # use first 10 SNPs\n",
    "result = EM(X, K=3, debug=True)\n",
    "predicted_ancestries = result[\"predicted_ancestries\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "fb0cd64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit(X_df)\n",
    "reduced = pca.transform(X_df)\n",
    "\n",
    "pca1, pca2 = [l[0] for l in reduced], [l[1] for l in reduced]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "8912152c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "for i, pred_ances in enumerate(predicted_ancestries):\n",
    "    print (pred_ances)\n",
    "    # countries = [l[1] for l in y]\n",
    "    unique_ancestries = list(set(pred_ances))\n",
    "    n = len(unique_ancestries)\n",
    "\n",
    "    data = {\"pca2\": pca2, \"pca1\": pca1, \"ancestry\": pred_ances}\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    color_list = [\"#%06x\" % random.randint(0, 0xFFFFFF) for _ in range(n)]\n",
    "    color_map = {uc: c for uc, c in zip(unique_ancestries, color_list)}\n",
    "\n",
    "    for ancestry, group in df.groupby(\"ancestry\"):\n",
    "        scatter = plt.scatter(group[\"pca2\"], group[\"pca1\"], label=ancestry, color=color_map[ancestry])\n",
    "\n",
    "    plt.xlabel(\"pc2\")\n",
    "    plt.ylabel(\"pc1\")\n",
    "    plt.title(f\"PC1 vs PC2, iteration {i}\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "3b92965d",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_ancestry = np.empty(N)\n",
    "for i in range(N):\n",
    "    actual_ancestry[i] = np.argmax(Z_df[i])\n",
    "\n",
    "snp_cts = [10, 25, 50, 100, 150, 200, 250]\n",
    "all_scores = []\n",
    "for snp_ct in snp_cts:\n",
    "    X = X_df[:, [i for i in range(snp_ct)]] # use first 10 SNPs\n",
    "    result = EM(X, K=2)\n",
    "\n",
    "    predicted_ancestries = result[\"predicted_ancestries\"]\n",
    "    best_predicted_ancestry = predicted_ancestries[-1]\n",
    "    score = adjusted_rand_score(actual_ancestry, best_predicted_ancestry)\n",
    "    all_scores.append(score)\n",
    "\n",
    "plt.scatter(snp_cts, all_scores)\n",
    "plt.title(\"Adjusted Rand Score vs SNP Count, for K = 2\")\n",
    "plt.xlabel(\"SNP Count\")\n",
    "plt.ylabel(\"Adjusted Rand Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "2fa024a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "components = [1, 2, 3, 4, 5]\n",
    "best_log_likelihoods = []\n",
    "for k in components:\n",
    "    X = Xnew_df[:, [i for i in range(100)]] # use first 100 SNPs\n",
    "    result = EM(X, K=k)\n",
    "    best_log_likelihoods.append(result[\"best_log_likelihood\"])\n",
    "\n",
    "plt.scatter(components, best_log_likelihoods)\n",
    "plt.xlabel(\"Component Number\")\n",
    "plt.ylabel(\"Log Likelihood\")\n",
    "plt.title(\"Log Likelihood vs. Component Number\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "4adb9277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "Best init gamma: [[2.97511489e-01 7.02488511e-01]\n",
      " [3.17613829e-04 9.99682386e-01]\n",
      " [6.20945430e-01 3.79054570e-01]\n",
      " ...\n",
      " [7.28502864e-01 2.71497136e-01]\n",
      " [1.03401610e-01 8.96598390e-01]\n",
      " [1.06242518e-02 9.89375748e-01]]\n",
      "Best log likelihood: -129163.5994772429\n",
      "Iteration 2\n",
      "Best init gamma: [[2.97511489e-01 7.02488511e-01]\n",
      " [3.17613829e-04 9.99682386e-01]\n",
      " [6.20945430e-01 3.79054570e-01]\n",
      " ...\n",
      " [7.28502864e-01 2.71497136e-01]\n",
      " [1.03401610e-01 8.96598390e-01]\n",
      " [1.06242518e-02 9.89375748e-01]]\n",
      "Best log likelihood: -129163.5994772429\n",
      "Iteration 3\n",
      "Best init gamma: [[2.97511489e-01 7.02488511e-01]\n",
      " [3.17613829e-04 9.99682386e-01]\n",
      " [6.20945430e-01 3.79054570e-01]\n",
      " ...\n",
      " [7.28502864e-01 2.71497136e-01]\n",
      " [1.03401610e-01 8.96598390e-01]\n",
      " [1.06242518e-02 9.89375748e-01]]\n",
      "Best log likelihood: -129163.5994772429\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[193], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m result \u001b[38;5;241m=\u001b[39m EM(Xnew_df, K\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[43mresults\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpis\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "result = EM(Xnew_df, K=2)\n",
    "print (result[\"best_pis\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
